{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Deep Learning best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='sigmoid')(x)\n",
    "\n",
    "model2 = models.Model(input_tensor, output_tensor)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.random((1000, 64))\n",
    "y = np.random.random((1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 11.6682\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 11.5772\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.5628\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 11.5552\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 11.5503\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 11.5467\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 11.5422\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 11.5395\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 11.5361\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 11.5334\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [11.668181190490722,\n",
       "  11.577159332275391,\n",
       "  11.562771240234374,\n",
       "  11.555203567504883,\n",
       "  11.550317649841309,\n",
       "  11.546717346191405,\n",
       "  11.542243560791016,\n",
       "  11.539547889709473,\n",
       "  11.536120765686036,\n",
       "  11.53344472503662]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feea23abb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), hist.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 57us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.529714073181152"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x, y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 11.5699\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 11.5515\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 11.5458\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 11.5416\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 11.5391\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 11.5365\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 11.5343\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 11.5324\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 11.5312\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 11.5303\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x, y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feea0e94e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), hist2.history['loss'], label='model2')\n",
    "plt.plot(range(1, 11), hist.history['loss'], label='model1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.527510368347167"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = model2.evaluate(x, y)\n",
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Input Models  \n",
    "Assuming there are two input (question and reference text) has been given to model and it will return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, models, Input\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocab_size = 10000\n",
    "ques_vocab_size = 10000\n",
    "ans_vocab_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining input for input text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(None,),dtype='int32', name='text')\n",
    "embeded_text = layers.Embedding(64, text_vocab_size)(input_text)\n",
    "encoded_text = layers.LSTM(32)(embeded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining input for question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ques = Input(shape=(None,), dtype='int32', name='ques')\n",
    "embeded_ques = layers.Embedding(32, ques_vocab_size)(input_ques)\n",
    "encoded_ques = layers.LSTM(16)(embeded_ques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatanating the input into one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.concatenate([encoded_text, encoded_ques], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = layers.Dense(ans_vocab_size, activation='softmax')(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model([input_text, input_ques], answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feeding data into model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = np.random.randint(1, text_vocab_size, size=(num_samples, max_len))\n",
    "input_ques = np.random.randint(1, ques_vocab_size, size=(num_samples, max_len))\n",
    "answer = np.random.randint(0, 1, size=(num_samples, ans_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.5730\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([input_text, input_ques], answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can use dictionary way as well\n",
    "#hist = model.fit({input_text:input_text, input_ques:input_ques}, answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Output Models  \n",
    "Assuming there are one input (image) has been given to model and it will return the age, income and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "income_groups = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Input\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embeded_posts = layers.Embedding(256, vocab_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embeded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Outputs\n",
    "age_pred = layers.Dense(1,  name='age')(x)\n",
    "income_pred = layers.Dense(income_groups, activation='softmax', name='income')(x)\n",
    "gender_pred = layers.Dense(1, activation='sigmoid', name='gender')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 50000)  12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    32000128    embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 50)           6450        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 45,659,700\n",
      "Trainable params: 45,659,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "model2 = models.Model(posts_input, [age_pred, income_pred, gender_pred])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Model with different losses and weightage\n",
    "model2.compile(optimizer='rmsprop', \n",
    "              loss={'age':'mse',\n",
    "                   'income':'categorical_crossentropy',\n",
    "                   'gender':'binary_crossentropy'}, \n",
    "              loss_weights={'age':0.25,\n",
    "                   'income':1.0,\n",
    "                   'gender':10.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    \"\"\"To generate one hot encoder\"\"\"\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_posts = np.random.randint(1, vocab_size, size=(num_samples, vocab_size))\n",
    "output_age = np.random.randint(10, 100, size=(num_samples, ))\n",
    "output_income = np.random.randint(income_groups, size=(num_samples, income_groups))\n",
    "output_gender = np.random.randint(0, 2, size=(num_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1, size=(num_samples, income_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26, 32,  2,  6, 46,  2, 35, 33, 17,  5, 31, 34, 25,  2, 32,  1,  7,\n",
       "        26, 41, 14, 21, 29, 49, 20, 28, 42, 31, 48, 43,  9, 35, 34,  7, 46,\n",
       "        46, 14, 15, 28, 39, 26, 31, 11, 17, 49, 29, 44,  0, 45, 43, 43],\n",
       "       [48, 26, 48, 25,  1, 34, 17, 46, 34, 48, 29, 18, 25, 14,  6, 28, 45,\n",
       "        27, 32, 43, 15, 20,  6,  1, 36, 26, 38,  1,  3, 42,  6, 14, 16, 24,\n",
       "        36, 26, 38, 16, 40, 38, 36, 37, 12,  2, 27, 38, 26, 30, 33, 25],\n",
       "       [27, 12, 45, 18, 46, 31,  9, 15, 24, 37, 15, 13, 40,  9, 33,  7, 41,\n",
       "        17, 31, 25, 39, 38, 36, 11, 13, 17,  6, 12, 23,  4, 21, 42, 31, 10,\n",
       "        14, 13, 46, 47, 14,  6,  0, 32, 12, 22,  5, 17, 44,  6,  6, 25]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_income[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,50000,50000]\n\t [[Node: embedding_3/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_3/embeddings/read, _recv_posts_0/_369)]]\n\t [[Node: loss_3/gender_loss/Mean_3/_449 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1332_loss_3/gender_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'embedding_3/Gather', defined at:\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-099c4a01f3ed>\", line 3, in <module>\n    embeded_posts = layers.Embedding(256, vocab_size)(posts_input)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1207, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,50000,50000]\n\t [[Node: embedding_3/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_3/embeddings/read, _recv_posts_0/_369)]]\n\t [[Node: loss_3/gender_loss/Mean_3/_449 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1332_loss_3/gender_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,50000,50000]\n\t [[Node: embedding_3/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_3/embeddings/read, _recv_posts_0/_369)]]\n\t [[Node: loss_3/gender_loss/Mean_3/_449 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1332_loss_3/gender_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-9dcb74bfa740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fitting the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_posts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_income\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_gender\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,50000,50000]\n\t [[Node: embedding_3/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_3/embeddings/read, _recv_posts_0/_369)]]\n\t [[Node: loss_3/gender_loss/Mean_3/_449 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1332_loss_3/gender_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'embedding_3/Gather', defined at:\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-099c4a01f3ed>\", line 3, in <module>\n    embeded_posts = layers.Embedding(256, vocab_size)(posts_input)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1207, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,50000,50000]\n\t [[Node: embedding_3/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](embedding_3/embeddings/read, _recv_posts_0/_369)]]\n\t [[Node: loss_3/gender_loss/Mean_3/_449 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1332_loss_3/gender_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "hist2= model2.fit(x=input_posts, y={'age':output_age, 'income':output_income, 'gender':output_gender}, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
