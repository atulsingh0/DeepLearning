{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Deep Learning best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='sigmoid')(x)\n",
    "\n",
    "model2 = models.Model(input_tensor, output_tensor)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.random((1000, 64))\n",
    "y = np.random.random((1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 11.6703\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 11.5907\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 11.5774\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.5690\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 11.5632\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 11.5598\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 11.5570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 11.5540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.5523\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.5496\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [11.670275924682617,\n",
       "  11.590682556152343,\n",
       "  11.57743783569336,\n",
       "  11.568971603393555,\n",
       "  11.563163284301758,\n",
       "  11.559791381835938,\n",
       "  11.557032073974609,\n",
       "  11.554011703491211,\n",
       "  11.552307090759278,\n",
       "  11.549598136901855]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe6d547b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), hist.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 94us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.547369522094726"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x, y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 11.6003\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 11.5604\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 11.5542\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.5519\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 11.5496\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 11.5477\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.5462\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.5446\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.5435\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 11.5420\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x, y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8XXWd//HXJ8vNvjRbF7qndAFa2lKWspQ2GRDBUUCZkVFBQHFQUUcdB535ucxvREdx4QeOWqGAiOhYARfKJqUUECktLaWQlu5tuiVNmqTZt+/vj3PS3qRJc5Pm5iS57+fjcR/33nPP8rlX6Tvf5ZxjzjlERETigi5ARESGBgWCiIgACgQREfEpEEREBFAgiIiIT4EgIiKAAkFERHwKBBERARQIIiLiSwi6gL7Iy8tzkydPDroMEZFhZd26dYedc/m9rTesAmHy5MmsXbs26DJERIYVM9sdyXrqMhIREUCBICIiPgWCiIgAw2wMQURiV0tLC6WlpTQ2NgZdypCVnJzM+PHjSUxM7Nf2CgQRGRZKS0vJyMhg8uTJmFnQ5Qw5zjkqKiooLS1lypQp/dqHuoxEZFhobGwkNzdXYdADMyM3N/eUWlAKBBEZNhQGJ3eqv09sBMLWv8BLPwy6ChGRIS02AmHnKlj1HWiuC7oSERHAO9H28OHDEa2zd+9elixZwqxZszjzzDO5++67o1JTbARCYTG0NcOul4OuRESkzxISEvjBD35ASUkJf/vb3/jJT37CO++8M+DHiY1AmLgQElJg+8qgKxGRYWzXrl3MnDmTT3ziE5x11ll85CMf4S9/+QsXXXQRp59+OmvWrKGyspKrr76aOXPmcMEFF7Bx40YAKioquPzyy5k3bx6f+tSncM4d2++vfvUrzjvvPObOncunPvUp2traOh137NixzJ8/H4CMjAxmzZrFvn37Bvz7xca008RkmHwRbHs+6EpEZAB8609v887+mgHd5xnjMvnG35/Z63rbtm3jd7/7HUuXLuXcc8/l17/+NS+//DJ//OMfufPOO5kwYQLz5s3jiSeeYOXKldxwww1s2LCBb33rW1x88cV8/etf58knn2Tp0qUAlJSU8Nvf/pZXXnmFxMREPv3pT/PII49www03dHv8Xbt2sX79es4///wB/f4QK4EAXrfRM1+Fqj2QPTHoakRkmJoyZQqzZ88G4Mwzz6S4uBgzY/bs2ezatYvdu3fz+9//HoCioiIqKiqorq5m9erVPPbYYwBcddVVjBo1CoDnn3+edevWce655wLQ0NBAQUFBt8eura3lgx/8ID/+8Y/JzMwc8O8WQ4FQ5D1vXwnnfDzQUkTk1ETyl3y0JCUlHXsdFxd37H1cXBytra0kJJz4z2rHdNDupoU657jxxhv5zne+c9LjtrS08MEPfpCPfOQjXHvttafyFXoUG2MIAPkzIPM0jSOISFQtWrSIRx55BIBVq1aRl5dHZmZmp+VPPfUUR44cAaC4uJjly5dTVlYGQGVlJbt3d75atXOOW265hVmzZvHFL34xarXHTiCYQeES2LEK2lqDrkZERqhvfvObrF27ljlz5nDHHXfw0EMPAfCNb3yD1atXM3/+fJ599lkmTvS6rs844wz+67/+i8svv5w5c+Zw2WWXceDAgU77fOWVV3j44YdZuXIlc+fOZe7cuaxYsWLAa7fwke6hbsGCBe6UbpCz6TFYfhPc8hxMOG/gChORqCspKWHWrFlBlzHkdfc7mdk659yC3raNnRYCwNTFgKnbSESkG7EVCKk5cNp8TT8VEelGbAUCeLON9q2FhqqgKxERGVJ6DQQzW2ZmZWa2KWzZdWb2tpm1m1mP/VJmlm1my81ss5mVmNnCsM9uN7Mt/n6+d+pfJUKFxeDaYeeLg3ZIEZHhIJIWwoPAFV2WbQKuBVb3su3dwNPOuZnA2UAJgJktAT4AzHHOnQnc1YeaT834BZCUqXEEEZEuej0xzTm32swmd1nW8Q97j9uZWSawCPi4v00z0Ox/fBvwXedck/9ZWZ8r76/4RJiyCLatBOe86agiIhLVMYSpQDnwgJmtN7P7zCzN/2w6cImZvWZmL5rZuVGs40SFRVC9Byq2D+phRUQ69OXy1wA333wzBQUFnHXWWVGrKZqBkADMB37qnJsH1AF3hH02CrgA+Ffgf62H5oaZ3Wpma81sbXl5+cBUduwyFpptJCLDw8c//nGefvrpqB4jmoFQCpQ6517z3y/HC4iOzx5znjVAO5DX3U6cc0udcwuccwvy8/MHprKcKZAzVdNPRaRPgrr8NXiXxMjJyYnq94vaxe2ccwfNbK+ZzXDObQGKgY47OjwBFAGrzGw6EAJO3nYaaIVFsOHX0NoECUm9ry8iQ8dTd8DBtwZ2n2Nmw3u/2+tqQV/+Opp6DQQzexRYDOSZWSnwDaASuAfIB540sw3OufeY2TjgPufclf7mtwOPmFkI2AHc5C9fBizzp7I2Aze6wb6GRmExvH4f7H3NG2QWEYlAkJe/jrZIZhld38NHj3ez7n7gyrD3G4ATzlPwZxx9NPIyo2DKJRCX4E0/VSCIDC8R/CUfLUFd/nowxN6Zyh2SMmDC+RpHEJEBFY3LXw+W2A0E8MYRDm6E2gGavSQiMS8al78GuP7661m4cCFbtmxh/Pjx3H///QNee2xd/rqrfW/AL5bAtb+AOf8wcPsVkQGny19HRpe/7q+xcyElR91GIiLEeiDExXl3UdvuX8ZCRCSGxXYggDf9tK4MDm3qfV0RCdRw6uIOwqn+PgqEwiXes65+KjKkJScnU1FRoVDogXOOiooKkpOT+72PqJ2pPGxkjoOCM7xxhIs+H3Q1ItKD8ePHU1payoBd02wESk5OZvz48f3eXoEA3vTTNUuhuR5CqUFXIyLdSExMZMqUKUGXMaKpywi8QGhrht2vBF2JiEhgFAgAky6EhGSNI4hITFMgACSmeKGg8xFEJIYpEDoUFsPhLVBdGnQlIiKBUCB0OHYXNXUbiUhsUiB0KJgFGWPVbSQiMUuB0MHMayXsWAXtJ96+TkRkpFMghCssgsYq2L8+6EpERAadAiHc1CWAaRxBRGKSAiFcWi6Mm6txBBGJSQqErgqLofR1aKwOuhIRkUGlQOiqsAhcG+xcHXQlIiKDSoHQ1YTzIJSubiMRiTm9BoKZLTOzMjPbFLbsOjN728zazazH+3SaWbaZLTezzWZWYmYLu3z+ZTNzZpZ3al9jAMUnwpRFsP153UVNRGJKJC2EB4EruizbBFwL9NavcjfwtHNuJnA2UNLxgZlNAC4D9kRa7KApLIKqPVC5I+hKREQGTa+B4JxbDVR2WVbinNtysu3MLBNYBNzvb9PsnKsKW+VHwFeAofdn+LRi71nTT0UkhkRzDGEqUA48YGbrzew+M0sDMLP3A/ucc29G8fj9lzMVRk3WOIKIxJRoBkICMB/4qXNuHlAH3GFmqcC/A1+PZCdmdquZrTWztYN667zCYtj1ErQ2D94xRUQCFM1AKAVKnXOv+e+X4wVEITAFeNPMdgHjgTfMbEx3O3HOLXXOLXDOLcjPz49iuV0UFkFzLZSuGbxjiogEKGqB4Jw7COw1sxn+omLgHefcW865AufcZOfcZLzgmO+vP3RMWQQWr24jEYkZkUw7fRR4FZhhZqVmdouZXWNmpcBC4Ekze8Zfd5yZrQjb/HbgETPbCMwF7hz4rxAlyZneOQkaWBaRGJHQ2wrOuet7+OjxbtbdD1wZ9n4D0ON5Cv46k3urITCFxfDCt6HuMKQNnVMlRESiQWcqn0xhEeC8eySIiIxwCoSTGTcXUkZpHEFEYoIC4WTi4r17JGxfqctYiMiIp0DoTWER1B6EsneCrkREJKoUCL0pLPKe1W0kIiOcAqE3WadB/kxNPxWREU+BEInCYtj9V2iuD7oSEZGoUSBEorAI2ppgz1+DrkREJGoUCJGYdCHEJ8E2dRuJyMilQIhEKBUmLdQ4goiMaAqESBUWQ3kJVO8LuhIRkahQIESq4y5qO14Itg4RkShRIESq4AxIH6PzEURkxFIgRMrMm2204wVobwu6GhGRAadA6IvCImg4Agc2BF2JiMiAUyD0ReES71nTT0VkBFIg9EVaHow9W9NPRWREUiD0VWExlK6BxpqgKxERGVAKhL4qLIL2Vtj1UtCViIgMKAVCX004H0Lpmn4qIiOOAqGvEkIw+RLYrkAQkZFFgdAfhUVwZBdU7gi6EhGRAdNrIJjZMjMrM7NNYcuuM7O3zazdzBacZNtsM1tuZpvNrMTMFvrLv+8v22hmj5tZ9sB8nUHScRkLdRuJyAgSSQvhQeCKLss2AdcCq3vZ9m7gaefcTOBsoMRf/hxwlnNuDvAu8NVICx4ScqZC9kTYrusaicjI0WsgOOdWA5VdlpU457acbDszywQWAff72zQ756r8188651r9Vf8GjO9H7cEx86af7lwNbS1BVyMiMiCiOYYwFSgHHjCz9WZ2n5mldbPezcBTUawjOgqLoPkolL4edCUiIgMimoGQAMwHfuqcmwfUAXeEr2Bm/w60Ao/0tBMzu9XM1prZ2vLy8iiW20dTLwWL1ziCiIwY0QyEUqDUOfea/345XkAAYGY3Au8DPuKccz3txDm31Dm3wDm3ID8/P4rl9lFyFow/V5exEJERI2qB4Jw7COw1sxn+omLgHQAzuwL4N+D9zrn6aNUQdYVFsH891FUEXYmIyCmLZNrpo8CrwAwzKzWzW8zsGjMrBRYCT5rZM/6648xsRdjmtwOPmNlGYC5wp7/8XiADeM7MNpjZzwbwOw2eacWA013URGRESOhtBefc9T189Hg36+4Hrgx7vwE44TwF59y0PtQ4dI2bB8nZ3vTT2R8KuhoRkVOiM5VPRVw8TF3sXcai52EQEZFhQYFwqgqL4OgBKN8cdCUiIqdEgXCqCou8Z00/FZFhToFwqrInQN50TT8VkWFPgTAQCoth9yvQ0hB0JSIi/aZAGAjTiqG1EXb/NehKRET6TYEwECZdCPEhdRuJyLCmQBgIoTSYuFCBICLDmgJhoBQWQdk7UHMg6EpERPpFgTBQOu6iplaCiAxTCoSBUnAmpBUoEERk2FIgDJS4OK/baMcL0N4edDUiIn2mQBhIhUVQXwEH3wy6EhGRPlMgDCRdxkJEhjEFwkBKz4cxczSOICLDkgJhoBUWwd7XoOlo0JWIiPSJAmGgTSuG9lbY+VLQlYiI9IkCYaBNOB8SU9VtJCLDjgJhoCUkweRLvLuoiYgMIwqEaCgsgsodULkz6EpERCKmQIgGXcZCRIYhBUI05E6DrIkKBBEZVnoNBDNbZmZlZrYpbNl1Zva2mbWb2YKTbJttZsvNbLOZlZjZQn95jpk9Z2Zb/edRA/N1hggzKFwCO1dDW0vQ1YiIRCSSFsKDwBVdlm0CrgVW97Lt3cDTzrmZwNlAib/8DuB559zpwPP++5FlWjE01UDp2qArERGJSK+B4JxbDVR2WVbinNtysu3MLBNYBNzvb9PsnKvyP/4A8JD/+iHg6j7W3Scr3jrAt/70djQPcaIpi8Di1G0kIsNGNMcQpgLlwANmtt7M7jOzNP+z0c65AwD+c0EU6+DdQ0d54JVdrNtd2fvKAyVlFJy2QNNPRWTYiGYgJADzgZ865+YBdfSja8jMbjWztWa2try8vF+FfPKSqeRnJPHtJ0twzvVrH/1SWAT73oD6QQwiEZF+imYglAKlzrnX/PfL8QIC4JCZjQXwn8t62olzbqlzboFzbkF+fn6/CklLSuCLl03njT1VPL3pYL/20S/TigEHO1YN3jFFRPopaoHgnDsI7DWzGf6iYuAd//UfgRv91zcCf4hWHR2uO2c8pxek899Pb6a5dZBuYDNuPiRlaRxBRIaFSKadPgq8Cswws1Izu8XMrjGzUmAh8KSZPeOvO87MVoRtfjvwiJltBOYCd/rLvwtcZmZbgcv891GVEB/HV6+cya6Ken792u5oH84TnwBTL/UCYTC7qkRE+iGhtxWcc9f38NHj3ay7H7gy7P0G4ITzFJxzFXgthkG1ZEYBC6fmcvfzW7n2nPFkJidG/6DTiqHkj1C+BQpmRv94IiL9FFNnKpsZX7tyFkfqW/jpqu2Dc9COu6ip20hEhriYCgSA2eOzuHruOJa9vJP9VQ3RP2D2RMg9XdNPRWTIi7lAAPjye2bggLuePem5dQOnsAh2vQItjYNzPBGRfojJQBg/KpWbLpzM4+v38fb+6ugfcFoxtDbAnlejfywRkX6KyUAA+PSSaWSlJPKdFZujf7LapIsgLlHjCCIypMVsIGSlJHJ70em8vO0wL77bvzOgI5aUDhMvUCCIyJAWs4EA8LELJjExJ5XvrNhMW3uUWwmFRXBoExwdxDOlRUT6IKYDIZQQx1eumMGWQ0f5/brS6B7s2F3UXojucURE+immAwHgqtljmTshmx88t4X65tboHWj0bEjLh3UPwtFD0TuOiEg/xXwgmBn/ftUsDtU0cf9LO6N3oLg4WPI12P8G3LsAXvs5tEUxgERE+ijmAwHg3Mk5XH7GaH724nbKjzZF70ALbobbXoXTzoGnvgK/WAx7Xut1MxGRwaBA8P3be2fS2NrO3c+/G90D5U2Djz0O1z3k3Sdh2eXwxGeg7nB0jysi0gsFgq8wP51/Om8ij67Zy7ay2ugezAzOvBo+swYu+jxs/A3cMx9evw/a26J7bBGRHigQwnz+704nJTGe/3568+AcMCkdLvtPuO2vMGYOPPkluK8Y9q0bnOOLiIRRIITJS0/iny+dynPvHGLNzkG87WX+DLjxT/DB+6HmAPyiGP70ed16U0QGlQKhi1sunsrozCS+vWKQ779sBrM/BJ99HS74NLzxMNxzDqx7CNoH6Q5vIhLTFAhdpITi+dJlM3hzbxV/3nhg8AtIzoQr7oR/fgnyZ8KfPgf3Xwb7Nwx+LSISUxQI3fjgOeOZOSaD7z2zmabWgAZ5R58JN62Aa34OVbth6WJvjKHhSDD1iMiIp0DoRnycccd7Z7K3soFf/W1PcIWYwdkfhs+uhfM+CWuXwT0LYP0j6kYSkQGnQOjBpdPzuXhaHves3Ep1Q0uwxaRkw5Xfh1tXQc4U+MOn4YH3wsFNwdYlIiOKAqEHZsZXr5xJdUML//PCtqDL8Yw9G25+Ft5/L1RshZ8vgqfugMZBuMmPiIx4CoSTOHNcFtfMO40H/rqL0iP1QZfjiYuD+R/zupHOuRFe+xncey5s/F8YzFlRIjLi9BoIZrbMzMrMbFPYsuvM7G0zazezBSfZdpeZvWVmG8xsbdjyuWb2t47lZnbeqX+V6Pjy5TMw4K5nBun+y5FKzYH3/Qg+uRIyT4PHPgkPvg/KSoKuTESGqUhaCA8CV3RZtgm4FlgdwfZLnHNznXPhwfE94FvOubnA1/33Q9K47BRuvngKT2zYz1ulQ7Br5rT58Im/wPt+7N2A52cXw7P/AU1Hg65MRIaZXgPBObcaqOyyrMQ5dyp/Mjsg03+dBew/hX1F3W2LC8lJC3HnYJ+sFqm4eFhwE9z+Bpx9Pfz1Hrj3PNj0mLqRRCRi0R5DcMCzZrbOzG4NW/4F4Ptmthe4C/hqTzsws1v9bqW15eVRvvdxDzKTE/lc0TRe3VHBC1vKAqkhImm58IF74Za/QFoeLL8JHr4aDm8NujIRGQaiHQgXOefmA+8FPmNmi/zltwH/4pybAPwLcH9PO3DOLXXOLXDOLcjPz49yuT37p/MnMTnXu/9ya9sQPwdgwrneFNUr74J96+F/FsJfvgXNdUFXJiJDWFQDwTm3338uAx4HOgaPbwQe81//Lmz5kBVKiOPfrpjJ1rJafhft+y8PhLh472S229fC7Ovg5R/CT86Hkj+pG0lEuhW1QDCzNDPL6HgNXI43GA3emMGl/usiYFj0aVxx1hjOmTSKHz73LnVNw+T2l+kFcM1P4aanICkTfvtReORDcODNoCsTkSEmkmmnjwKvAjPMrNTMbjGza8ysFFgIPGlmz/jrjjOzFf6mo4GXzexNYA3wpHPuaf+zTwI/8D+7EwgfXxiyzIyvXTmT8qNN/OKlHUGX0zeTLoRPrYb3fMe7befPF8HPLoE1v9D1kUQEABuSs2Z6sGDBArd27dreV4yy2361jhffLWfVvy6mICM56HL6rr4S3loO638JB9+C+CSY9ffeCW+TF3knv4nIiGFm67pM/e+W/svvh69cMZPm1nZ+9Nyw6Ok6UWoOnH8r/PPLcOuLXhBsfQ5++QH4f3Phxe9B9TAYJxGRAaVA6IcpeWl89IJJ/Pb1PWw9NMxPABs3F676AXx5C1x7H4yaBC98G350Fjx8Lbz9OLQ2BV2liAwCBUI/fa74dNJCCXz3qUG6/3K0JabAnOu8W3l+bgMs+jKUb4bffRx+MBOe/iocejvoKkUkihQI/ZSTFuK2JYU8v7mMV7dXBF3OwMqZAkX/AV94Cz7ye5jiDz7/9EJYusS7L4OusCoy4mhQ+RQ0trRRdNcqctOT+MNnLiIuzoIuKXrqDntXVF3/MJS9AwkpcMYHvPGHSRd5N/MRkSFJg8qDIDkxni9dPoO39lXzp41D+nJMpy4tDxZ+Gm77K3xiJZz9j7D5SXjwKrhnPrz0A6gJ4B7UIjJg1EI4Re3tjvfd8zLVDS08/6VLSU6MD7qkwdNcD+/8wWs17H4FLA5OvxzmfRSmXwHxiUFXKCKohTBo4uKMr105i31VDfzy1V1BlzO4Qqkw93q4aYV3pdWLvgD7N3hnQ/9wlncZ7vJ3g65SRCKkFsIAuXHZGtbvOcLqrywhOzUUdDnBaWuFbX/xWg3vPg3trTDhfK/VcOY1kJQRdIUiMUcthEH21StnUtvUyj0rh8j9l4MSnwAzroAPPwJfLIHL/q93aYw/3g53zYA/fMa7dMYw+kNEJFYoEAbIzDGZfOic8fzy1V3sqRgi918OWnoBXPQ5+MwauPlZOOsa2PQ4LLscfnIevHI3HN6mcBAZItRlNIAOVjey+K4X+LtZo7n3n+YHXc7Q1FTrnf28/mHY+5q3LHM8TF3sPaYsgozRwdUnMgJF2mWUMBjFxIoxWcl88pKp3LNyG5+4pIq5E7KDLmnoSUr3zl2Y/zGo3AHbX4Adq2Dzn2HDr7x1Cs44HhCTLtS4g8ggUQthgNU2tbL4+y8wNT+d3956AaYTtiLT3ubdo2Hni15A7H4V2pogLgFOW3A8IMYv0HRWkT6KtIWgQIiCh/+2m//zxCZ+ccMCLjtD3R/90tLgdSnt8ANi/3rAQSjdazVMXew9Cs7QWdIivVAgBKilrZ33/Hg1BjzzhUUkxGvs/pTVV8Kul4+3ICr82VxpBTD1UphyqRcQ2RMCLFJkaNIYQoAS4+O444qZ3PrwOn7z+l4+esGkoEsa/lJz4Iz3ew+Aqr3Hw2HHi/DW77zlOYVhA9SXQMqoQMoVGY7UQogS5xz/+PO/seNwLav+dQnpScreqHEOykr8cFjlXUajuRYw734PUxd7jwkXQOIwvMOdyClSl9EQsGFvFVf/5BU+VzSNL14+I+hyYkdbC+xbdzwgSl/3zpiOT4KJFxwPiLFnQ1wMXXtKYpYCYYj47K/f4PmSMlb962JGZ+qv00A0HfVmLXUERJl/o5/kbK9bacqlUDALck/3TqbTILWMMAqEIWJPRT3FP1zFtfPG898fmhN0OQJQWwY7V8OOF2D7KqgJu390UhbkTfPCIc9/5J4OOVPV3STDlgaVh4iJuancsHAyD7yyk5svnsKMMTrJKnDpBTD7Q97DOaguhcPvejOXDr8Lh7fCrpdg42+Ob2NxkD0R8qb7YTHt+Gu1KmSE6LWFYGbLgPcBZc65s/xl1wHfBGYB5znnuv2z3cx2AUeBNqA1PKHM7Hbgs0Ar8KRz7iu9FTscWwgAVfXNLPreC8yfNIoHbzov6HIkUk21XkiEB0XFVu/6S60Nx9dLyjzekggPCrUqZIgYyBbCg8C9wC/Dlm0CrgV+HsH2S5xzh7sUtwT4ADDHOddkZgUR7GfYyk4N8dmiady5YjOr3y1n0fT8oEuSSCSle7OUxs3tvLy9HWr2+eHQ8Xi351ZF1+6nvOlqVciQ1GsgOOdWm9nkLstKgFO5LMNtwHedc03+/sr6u6Ph4oaFk/nlq7u5YdkaZp+WxeIZ+Vw6PZ+5E7J14tpwExfnnQCXPQEKizp/1qlV4QdFxVZvKmxL2FVwkzIh129NdIxZ5E6DUZN07SYJTESDyn4g/Lmjyyhs+SrgyyfpMtoJHAEc8HPn3FJ/+QbgD8AVQKO/j9d72MetwK0AEydOPGf37t2RfK8haV9VA0+s38eqLWW8saeKtnZHVkoiF5+ex+Lp+Vw6I5+CDHUxjEidWhXbjgfF4W2dB7XBO5kueyJkT+ry7D+S0oP5DjJsDegso1MIhHHOuf1+l9BzwO1+i2MTsBL4PHAu8FtgquulmOE6htCd6voWXt52mFVbynjx3XLKjjYBcOa4TBbPyGfxjALmqfUQG5rr/FbFdqjac+IjfLwCIDW3c0BkTwoLjQkQSgvme8iQNSRmGTnn9vvPZWb2OHAesBooBR7zA2CNmbUDeUB5NOsZSrJSE7lqzliumjMW5xzvHKhh1ZZyXtxSzs9e3MFPXthORnICl5yex+LpBVw6I1/nMYxUoTTvJLmxZ5/4mXNQV+6Hw27v+Yj/fOgd2PK0d1XYcKl5x8NiVJdWRtYE717YIt2IWiCYWRoQ55w76r++HPhP/+MngCJglZlNB0LA4e73NPKZGWeOy+LMcVl8Zsk0ahpbeGXrYVZtKWfVu2WseOsgALPG+q2H6fnMnzSKRLUeRj4zbwA6vcC79HdX7e1+YOzuHBpVe+DgW7BlBbQ1d94mraBLC8MPjFGTIGs8JKYMzneTISeSaaePAovx/oI/BHwDqATuAfKBKmCDc+49ZjYOuM85d6WZTQUe93eTAPzaOfdtf58hYBkwF2jG63Za2VuxI6nLKFLOOTYfPOqFw5Yy1u0+Qmu7IyMpgYum5R3rXhqTpdaDdKO9HWoPhXVB7erSJbUX2ls6b5M+BnKmwKgp3nPO1OOvU0ZpdtQwpDOVR6ijjS28ss1vPWwp52BNIwAzx2Rw6YwNcH7EAAAMq0lEQVR8Fk8v4JxJowglqPUgEWhvg6MHwwJit9cldWSnd0e7owc6r5+U5YdER2BMPf46Y6w3A0uGHAVCDHDO8e6hWlZtKWPVlnLW7q6kpc2RnpTAhYW5LJ5RwOIZ+YzLVheA9FNzvRcSlTugcqcfFH5YVO/1LhrYISEZRk0+3poID4ysCZAQCuxrxDoFQgyqbWo91np4cUsZ+6u91sP00eleOEzPZ8HkHLUeZGC0tXqh0NGaqNwJR3YdD47w8y4szhufCO9+Cn+tmVFRpUCIcc45tpbVHpvWuman13pIDcVzYWEeZ4zLZExmMmOzkhmdmcyYrGRGpSbqHtAyMJzzxi6OtSq6tDAaKjuvn1bQufspZwpkjvOm2KbmemMXupd2vykQpJO6plb+ur2CVVvKeGnrYfYeqafr//ShhDjGZCYzJjOZ0VnJjMlMYnRmMmOzUhiT5b0uyEhWC0NOXUPV8XA4Fhi7vNc1+7rfJinLu3NeR0ik5nZ53+WzlFG634VPgSAn1dLWTvnRJg7WNHKw2nscqmnkYE0jBzpeVzfS1Np+wrZ56UmMyUrygsMPkDFZ/sMPk4ykBLU2pH9aGryB7dpDUF/hPyqPv26o7LwsvGuqE4OU7LCAyOk+OMKXJWePyIHxIXFimgxdifFxjMtOOemAs3OO6oYWDlR7QXHIfz7oP5ceaWDd7iMcqW85Ydu0ULzfyugcGOEBkpeeRHycQkO6SEyBgpneIxLN9SeGRHiAdDyqS+HgRqg7fOLJfB0szmtZhIdF5jhvUDz8vI3U3BE5/VaBID0yM7JTQ2Snhpg1NrPH9Rpb2o61KA7WeK2L8FbGazsrOVTTSGt759ZofJyRn57UqXuqIzC8cY0kCjLV2pBehFK9R9b4yNZ3zmtVdAqMHoKkcod3M6Wmms77SEw9fuZ3xyVDOk7wy5owbK9mq0CQU5acGM+k3DQm5fY8U6S93XG4rolD1X43VU0jB6sbOFTTxKGaRnaU1/Hq9gpqGltP2DY1FM+YzGQKMpOOdUmNzuhocWhsQ/rIzJvVFErz/hGPREOVN6Oq42S+jnM2qvfCvrXQcKTz+gnJXkB1tCiyJviXD/GDI33MkOyaUiDIoIiLMwoyvH+4Z5PV43r1za3HQqLjcbD6+Pu1u49QVtNEc9uJYxu5aaFjM6ZGd9PiGJ2ZRE5aSK0N6buUbO8xZnb3nzcdPR4U1XvDLiGyFw5shPouV+aJD0HmaWGti0mdWxwZYyF+8P95ViDIkJIaSmBKXgJT8npubTjnOFLf4g2EHz0+ttERJAerG9lYWsXh2uYTtg3Fx5GfkXRsALzAD47ctBB56V5g5KaHyE1LIiWkGSoSoaQMGH2G9+hOc503hhF+2ZCOFsfW57wB9HBxCd7YRUcXVPZEmPMPkFsY1a+hQJBhx8zISQuRkxbiDHoe22hubafsaGOnFkfH4PihmiZKDtTwwpZG6pvbut0+NRTvB0QSuWkhctNC5KSHyEvrHBy56V4tyYkKEOlBKA3yZ3iP7rQ0eoFR3eU6U1V7YMcq7xIiky5UIIj0VyghjvGjUhk/qufLPTvnqG1qpbKumYq6Zipqm6msa+JwbbO3rLaJirpmDlY38s7+Girqmmhp636qdnpSQlhQeGGR0/E6PUROWlLY6xBJCQoQ8SUm+/fjntb9563NgzJIrUCQmGZmZCQnkpGceNJB8Q7OOY42tR4LjopaL0gq65o5XNvkh0gz+6oa2VhaTWVd8wmzqzpkJCUcC4fc9CRyUkNkpyaSlZpIdkqIrJRE731K4rHX6ZpxFZsG6TpQCgSRPjAzMpMTyUxOPOk4RwfnHDUNrVTUNYW1QI63PLwwaWJvZT0b9lZR3dBCczcnA3aIjzMvHFI6gqMjLEKdguN4kISOvdb9M6Q3CgSRKDIzsvy/+qfmR7ZNY0sbVfUtVDU0U13fQlVDC9X1LVQ3eMuq/NfVDS0crm1me3kdVfXN3U7ZDZcWiic7NUSmHyjHQsNvkXS8z/YDJjs1kVGpIZIT49QqiREKBJEhJjkxnjFZ8X2+6VFbu6OmoSM4Wqiqbz4WHB0h4j17y7eV1R4Lm+6m8XYIJcQxyg+HrBTv2WuFdISG/zolkVFpoWOBovNChh8FgsgIER9njEoLMSqtb/3NzjkaW9q9FklDC0fqvNA4Uu8FSFW91yo54j/vOFzrf9bc4wA7eLO0jodHWGiEBcqoLp9lpSSSoK6twCgQRGKcmZESiicllMLYrMhvpuSco765jaqGFo7UNR/r5jpS30J1fedAOVLfzIHqmmPvexhnByAjOYFRqSEykhNIS0ogPcl7TgvFe89JCaQnxZMaCvssKZ70pISwZfGkhRKI07Wy+kSBICL9YmbH/oE+rQ935Wtv92ZqVXe0OvzurSN1Ha+95bWNrdQ2tVJ2tJG6w23UNbV6jx7OG+lOSmL8sQBJ6xIs3QdNAqmh+LCgSSAzJYGslMSYmCasQBCRQRXnz5TKSklkYm7P54j0pL3dUd/SRn2TFxh1TW3UNrVS33z8fZ3/mbcsPExaOVzbzO6Ken/dyAMmJTG+0zTgrtOCs/wxluwun2UkJw6bq/oqEERkWImLM9L9v+YLBmB/7e2OhpbwEGk7Fha1Ta3UNLZS7Q/QHxucb2hhT2U9G0u99w0tPYeKmXfOScfU4OzUxGMzvU4IlS7nn6SG4gd1hlevgWBmy4D3AWXOubP8ZdcB3wRmAec557q9a42Z7QKOAm1Aa9cbNJjZl4HvA/nOucMn7kFEJLri4o53ffU3YJpa27wZXWFTgsPDoyZs1ldVQwv7qhqOrdvTiYsAifHHW1N3XjOb86fm9rPCyETSQngQuBf4ZdiyTcC1wM8j2H5Jd//Ym9kE4DJgTwT7EBEZspIS4inIiKcgo29ThZ1z1DW3+QHS3ClUqsKCpaahhcyU6N9TutdAcM6tNrPJXZaVAKfalPkR8BXgD6eyExGR4crsePdXXwbmoyXaE34d8KyZrTOzWzsWmtn7gX3OuTejfHwREYlQtAeVL3LO7TezAuA5M9sMrAX+Hbg8kh34QXIrwMSJEd7dSERE+iyqLQTn3H7/uQx4HDgPKASmAG/6g87jgTfMbEwP+1jqnFvgnFuQnx/hxWBERKTPohYIZpZmZhkdr/FaBJucc2855wqcc5Odc5OBUmC+c+5gtGoREZHe9RoIZvYo8Coww8xKzewWM7vGzEqBhcCTZvaMv+44M1vhbzoaeNnM3gTWAE86556OztcQEZFTFckso+t7+OjxbtbdD1zpv94BnB3B/if3to6IiESfLisoIiKAAkFERHzm3EmuQzvEmFk5sDvoOk5RHqDLdByn3+M4/Rad6ffo7FR+j0nOuV6naQ6rQBgJzGxt12s6xTL9Hsfpt+hMv0dng/F7qMtIREQABYKIiPgUCINvadAFDDH6PY7Tb9GZfo/Oov57aAxBREQAtRBERMSnQBgkZjbBzF4wsxIze9vMPh90TUEzs3gzW29mfw66lqCZWbaZLTezzf7/RxYGXVNQzOxf/P9GNpnZo2bWt7vODHNmtszMysxsU9iyHDN7zsy2+s+jonFsBcLgaQW+5JybBVwAfMbMzgi4pqB9HigJuogh4m7gaefcTLxLvsTk72JmpwGfAxb4t+yNBz4cbFWD7kHgii7L7gCed86dDjzvvx9wCoRB4pw74Jx7w399FO8/+NOCrSo4ZjYeuAq4L+hagmZmmcAi4H4A51yzc64q2KoClQCkmFkCkArsD7ieQeWcWw1Udln8AeAh//VDwNXROLYCIQD+LUnnAa8FW0mgfox3C9X2oAsZAqYC5cADfhfaff4l42OOc24fcBfevdYPANXOuWeDrWpIGO2cOwDeH5dAQTQOokAYZGaWDvwe+IJzriboeoJgZu8Dypxz64KuZYhIAOYDP3XOzQPqiFKXwFDn941/AO8mWuOANDP7aLBVxQ4FwiAys0S8MHjEOfdY0PUE6CLg/f4d834DFJnZr4ItKVClQKlzrqPFuBwvIGLR3wE7nXPlzrkW4DHgwoBrGgoOmdlYAP+5LBoHUSAMEjMzvD7iEufcD4OuJ0jOua8658b798L4MLDSORezfwX6dwvca2Yz/EXFwDsBlhSkPcAFZpbq/zdTTIwOsHfxR+BG//WNwB+icZBeb5AjA+Yi4GPAW2a2wV/2NefcipNsI7HjduARMwsBO4CbAq4nEM6518xsOfAG3sy89cTYGcv+XSoXA3n+nSm/AXwX+F8zuwUvNK+LyrF1prKIiIC6jERExKdAEBERQIEgIiI+BYKIiAAKBBER8SkQREQEUCCIiIhPgSAiIgD8f2g7GYoYbErjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe45e5bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), hist2.history['loss'], label='model2')\n",
    "plt.plot(range(1, 11), hist.history['loss'], label='model1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 73us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.539799514770507"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = model2.evaluate(x, y)\n",
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Input Models  \n",
    "Assuming there are two input (question and reference text) has been given to model and it will return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, models, Input\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocab_size = 10000\n",
    "ques_vocab_size = 10000\n",
    "ans_vocab_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining input for input text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(None,),dtype='int32', name='text')\n",
    "embeded_text = layers.Embedding(64, text_vocab_size)(input_text)\n",
    "encoded_text = layers.LSTM(32)(embeded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining input for question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ques = Input(shape=(None,), dtype='int32', name='ques')\n",
    "embeded_ques = layers.Embedding(32, ques_vocab_size)(input_ques)\n",
    "encoded_ques = layers.LSTM(16)(embeded_ques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatanating the input into one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.concatenate([encoded_text, encoded_ques], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = layers.Dense(ans_vocab_size, activation='softmax')(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model([input_text, input_ques], answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feeding data into model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = np.random.randint(1, text_vocab_size, size=(num_samples, max_len))\n",
    "input_ques = np.random.randint(1, ques_vocab_size, size=(num_samples, max_len))\n",
    "answer = np.random.randint(0, 1, size=(num_samples, ans_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.6010\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([input_text, input_ques], answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can use dictionary way as well\n",
    "#hist = model.fit({input_text:input_text, input_ques:input_ques}, answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Output Models  \n",
    "Assuming there are one input (image) has been given to model and it will return the age, income and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "income_groups = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Input\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embeded_posts = layers.Embedding(256, vocab_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embeded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Outputs\n",
    "age_pred = layers.Dense(1,  name='age')(x)\n",
    "income_pred = layers.Dense(income_groups, activation='softmax', name='income')(x)\n",
    "gender_pred = layers.Dense(1, activation='sigmoid', name='gender')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 50000)  12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    32000128    embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 50)           6450        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 45,659,700\n",
      "Trainable params: 45,659,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "model2 = models.Model(posts_input, [age_pred, income_pred, gender_pred])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Model with different losses and weightage\n",
    "model2.compile(optimizer='rmsprop', \n",
    "              loss={'age':'mse',\n",
    "                   'income':'categorical_crossentropy',\n",
    "                   'gender':'binary_crossentropy'}, \n",
    "              loss_weights={'age':0.25,\n",
    "                   'income':1.0,\n",
    "                   'gender':10.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    \"\"\"To generate one hot encoder\"\"\"\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_posts = np.random.randint(1, vocab_size, size=(num_samples, max_len))\n",
    "output_age = np.random.randint(10, 100, size=(num_samples, ))\n",
    "output_income = np.random.randint(1, income_groups, size=(num_samples, ))\n",
    "one_hot_output = get_one_hot(output_income, income_groups)\n",
    "output_gender = np.random.randint(0, 2, size=(num_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 18, 38])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_income[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_output[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gender[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gender[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2817,  6252,   659, 18130,  9888,  6469,  2447, 46692, 36762,\n",
       "       35873,  9447, 12499, 21298, 30468, 40025, 17588, 11720, 36548,\n",
       "       42938, 42902, 38105, 22476, 29557, 39767, 33971, 29113,  7921,\n",
       "       22386, 40388,   992, 21953, 18627, 42606,  7782, 11199, 36273,\n",
       "       43271,  1108, 27825, 31523,  3335, 46435, 16208, 40667, 37586,\n",
       "        6027, 12927, 15258,  6683, 39852, 34761,  6255, 37059, 38226,\n",
       "       35165, 26898, 27670, 19616, 21171, 14207, 33779, 15459, 21227,\n",
       "       44632, 42014, 39968, 30989, 48748, 45770, 20108, 28276, 37946,\n",
       "       25385, 24415, 12021, 29389, 47827,   851, 13177, 29787, 34974,\n",
       "       48011, 43583, 39869,  5441, 33990, 49440, 42538,  2338, 33279,\n",
       "        9130,  8930, 31868, 13960, 23327, 22788,  5467, 38555, 38655, 14384])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_posts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "computed output size would be negative\n\t [[Node: conv1d_3/convolution/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv1d_3/convolution/ExpandDims, conv1d_3/convolution/ExpandDims_1)]]\n\t [[Node: loss_3/age_loss/Mean_3/_425 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1800_loss_3/age_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv1d_3/convolution/Conv2D', defined at:\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-099c4a01f3ed>\", line 8, in <module>\n    x = layers.Conv1D(256, 5, activation='relu')(x)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 160, in call\n    dilation_rate=self.dilation_rate[0])\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3294, in conv1d\n    data_format=tf_data_format)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 661, in convolution\n    op=op)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 331, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 653, in op\n    name=name)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 114, in _non_atrous_convolution\n    name=scope)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2062, in conv1d\n    data_format=data_format)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 403, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): computed output size would be negative\n\t [[Node: conv1d_3/convolution/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv1d_3/convolution/ExpandDims, conv1d_3/convolution/ExpandDims_1)]]\n\t [[Node: loss_3/age_loss/Mean_3/_425 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1800_loss_3/age_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: computed output size would be negative\n\t [[Node: conv1d_3/convolution/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv1d_3/convolution/ExpandDims, conv1d_3/convolution/ExpandDims_1)]]\n\t [[Node: loss_3/age_loss/Mean_3/_425 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1800_loss_3/age_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-933534109e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fitting the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_posts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mone_hot_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_gender\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: computed output size would be negative\n\t [[Node: conv1d_3/convolution/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv1d_3/convolution/ExpandDims, conv1d_3/convolution/ExpandDims_1)]]\n\t [[Node: loss_3/age_loss/Mean_3/_425 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1800_loss_3/age_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv1d_3/convolution/Conv2D', defined at:\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-099c4a01f3ed>\", line 8, in <module>\n    x = layers.Conv1D(256, 5, activation='relu')(x)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 160, in call\n    dilation_rate=self.dilation_rate[0])\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3294, in conv1d\n    data_format=tf_data_format)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 661, in convolution\n    op=op)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 331, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 653, in op\n    name=name)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 114, in _non_atrous_convolution\n    name=scope)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2062, in conv1d\n    data_format=data_format)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 403, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sanmati/anaconda3/envs/fastai2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): computed output size would be negative\n\t [[Node: conv1d_3/convolution/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv1d_3/convolution/ExpandDims, conv1d_3/convolution/ExpandDims_1)]]\n\t [[Node: loss_3/age_loss/Mean_3/_425 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1800_loss_3/age_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "hist2= model2.fit(x=input_posts, y={'age':output_age, 'income':one_hot_output, 'gender':output_gender}, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
