{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_labels),(test_image, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.shape  # 3-D Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_image)  # total count of input img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.Sequential()\n",
    "net.add(layers.Dense(512, activation='relu', input_shape=(28,28)))\n",
    "net.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation\n",
    "net.compile(optimizer='rmsprop',\n",
    "           loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the input data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image[0].shape  # 1 image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping it \n",
    "#train_image = train_image.reshape((60000, 28*28))\n",
    "train_img = train_image.reshape((60000, -1))\n",
    "# scaling the value of pixels in the 0,1 range by dividing 255\n",
    "train_img = train_image.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing the same for test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping it \n",
    "test_img = test_image.reshape((10000, 28*28))\n",
    "# scaling the value of pixels in the 0,1 range by dividing 255\n",
    "test_img = test_image.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the labels as Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_8 to have 3 dimensions, but got array with shape (60000, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-3dd250eadcd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1593\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1594\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1431\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1432\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    108\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_8 to have 3 dimensions, but got array with shape (60000, 1)"
     ]
    }
   ],
   "source": [
    "net.fit(train_img, train_labels, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24480f35128>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8ERfiBoP4P/asyf+mjVg0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x244814de780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_img[5]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x244812e0a90>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8ERfiBoP4P/asyf+mjVg0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24480f63be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_image[5], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 2 3 4] (6,)\n",
      "[[0 2 1]\n",
      " [2 3 4]] (2, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "a = numpy.array([0,2,1,2,3,4])\n",
    "print(a, a.shape)\n",
    "b = a.reshape((2,3))\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
